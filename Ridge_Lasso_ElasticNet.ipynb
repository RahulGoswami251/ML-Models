{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import datasets \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading pre-defined Boston Dataset\n",
    "boston_dataset = datasets.load_boston()\n",
    "#print(boston_dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),\n",
       " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
       " 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
       " 'filename': 'C:\\\\Users\\\\Rahul\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\boston_house_prices.csv'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
      "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
      "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
      "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
      "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
      "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
      "\n",
      "   PTRATIO       B  LSTAT  House Price  \n",
      "0     15.3  396.90   4.98         24.0  \n",
      "1     17.8  396.90   9.14         21.6  \n",
      "2     17.8  392.83   4.03         34.7  \n",
      "3     18.7  394.63   2.94         33.4  \n",
      "4     18.7  396.90   5.33         36.2  \n"
     ]
    }
   ],
   "source": [
    "#Load the data and divide into X and Y varaiable\n",
    "boston_pd = pd.DataFrame(boston_dataset.data) \n",
    "boston_pd.columns = boston_dataset.feature_names \n",
    "boston_pd_target = np.asarray(boston_dataset.target) \n",
    "boston_pd['House Price'] = pd.Series(boston_pd_target) \n",
    "\n",
    "# input \n",
    "X = boston_pd.iloc[:, :-1]\n",
    "#output \n",
    "Y = boston_pd.iloc[:, -1]\n",
    "print(boston_pd.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((379, 13), (379,), (127, 13), (127,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(boston_pd.iloc[:, :-1],\n",
    "                                                    boston_pd.iloc[:, -1],\n",
    "                                                    test_size=0.25)\n",
    "\n",
    "(x_train.shape, y_train.shape,x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared Error on test set :  22.469563807182816\n",
      "    Columns  Coefficient Estimate\n",
      "0      CRIM             -0.087600\n",
      "1        ZN              0.047177\n",
      "2     INDUS              0.021686\n",
      "3      CHAS              3.181757\n",
      "4       NOX            -20.461170\n",
      "5        RM              3.919371\n",
      "6       AGE              0.006958\n",
      "7       DIS             -1.500791\n",
      "8       RAD              0.328703\n",
      "9       TAX             -0.010216\n",
      "10  PTRATIO             -0.989119\n",
      "11        B              0.011442\n",
      "12    LSTAT             -0.534860\n"
     ]
    }
   ],
   "source": [
    "# Apply multiple Linear Regression Model \n",
    "lreg = LinearRegression() \n",
    "lreg.fit(x_train, y_train) \n",
    "\n",
    "# Generate Prediction on test set \n",
    "lreg_y_pred = lreg.predict(x_test) \n",
    "\n",
    "# calculating Mean Squared Error (mse) \n",
    "mean_squared_error = np.mean((lreg_y_pred - y_test)**2) \n",
    "print(\"Mean squared Error on test set : \", mean_squared_error) \n",
    "\n",
    "# Putting together the coefficient and their corrsponding variable names \n",
    "lreg_coefficient = pd.DataFrame() \n",
    "lreg_coefficient[\"Columns\"] = x_train.columns \n",
    "lreg_coefficient['Coefficient Estimate'] = pd.Series(lreg.coef_) \n",
    "print(lreg_coefficient) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Coefficient Estimate', ylabel='Columns'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.barplot(x='Coefficient Estimate' , y='Columns', data=lreg_coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.264121917018425\n",
      "    Columns  Coefficient Estimate\n",
      "0      CRIM             -0.077067\n",
      "1        ZN              0.048985\n",
      "2     INDUS             -0.014702\n",
      "3      CHAS              2.901157\n",
      "4       NOX            -10.771613\n",
      "5        RM              4.009618\n",
      "6       AGE             -0.000687\n",
      "7       DIS             -1.351872\n",
      "8       RAD              0.312778\n",
      "9       TAX             -0.011377\n",
      "10  PTRATIO             -0.889728\n",
      "11        B              0.012431\n",
      "12    LSTAT             -0.549512\n"
     ]
    }
   ],
   "source": [
    "# import ridge regression from sklearn library \n",
    "from sklearn.linear_model import Ridge \n",
    "\n",
    "# Train the model \n",
    "ridgeR = Ridge(alpha = 1) \n",
    "ridgeR.fit(x_train, y_train) \n",
    "y_pred = ridgeR.predict(x_test) \n",
    "\n",
    "# calculate mean square error \n",
    "mean_squared_error_ridge = np.mean((y_pred - y_test)**2) \n",
    "print(mean_squared_error_ridge) \n",
    "\n",
    "# get ridge coefficient and print them \n",
    "ridge_coefficient = pd.DataFrame() \n",
    "ridge_coefficient[\"Columns\"]= x_train.columns \n",
    "ridge_coefficient['Coefficient Estimate'] = pd.Series(ridgeR.coef_) \n",
    "print(ridge_coefficient) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### # import Lasso regression from sklearn library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error on test set 22.468569710130346\n",
      "    Columns  Coefficient Estimate\n",
      "0      CRIM             -0.067448\n",
      "1        ZN              0.050028\n",
      "2     INDUS             -0.035933\n",
      "3      CHAS              2.058720\n",
      "4       NOX             -3.032113\n",
      "5        RM              3.993601\n",
      "6       AGE             -0.004560\n",
      "7       DIS             -1.201377\n",
      "8       RAD              0.301226\n",
      "9       TAX             -0.012510\n",
      "10  PTRATIO             -0.822018\n",
      "11        B              0.013221\n",
      "12    LSTAT             -0.568736\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso \n",
    "\n",
    "# Train the model \n",
    "lasso = Lasso(alpha = 0.05) \n",
    "lasso.fit(x_train, y_train) \n",
    "y_pred1 = lasso.predict(x_test) \n",
    "\n",
    "# Calculate Mean Squared Error \n",
    "mean_squared_error = np.mean((y_pred1 - y_test)**2) \n",
    "print(\"Mean squared error on test set\", mean_squared_error) \n",
    "lasso_coeff = pd.DataFrame() \n",
    "lasso_coeff[\"Columns\"] = x_train.columns \n",
    "lasso_coeff['Coefficient Estimate'] = pd.Series(lasso.coef_) \n",
    "\n",
    "print(lasso_coeff) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### # import Lasso regression from sklearn library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on test set 22.44544054228355\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Columns</th>\n",
       "      <th>Coefficient Estimate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>-0.070143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZN</td>\n",
       "      <td>0.050987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>-0.042388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAS</td>\n",
       "      <td>2.221489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX</td>\n",
       "      <td>-2.951537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RM</td>\n",
       "      <td>3.904802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGE</td>\n",
       "      <td>-0.005010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DIS</td>\n",
       "      <td>-1.228034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RAD</td>\n",
       "      <td>0.306087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAX</td>\n",
       "      <td>-0.012598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>-0.828106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>0.013149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>-0.573296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Columns  Coefficient Estimate\n",
       "0      CRIM             -0.070143\n",
       "1        ZN              0.050987\n",
       "2     INDUS             -0.042388\n",
       "3      CHAS              2.221489\n",
       "4       NOX             -2.951537\n",
       "5        RM              3.904802\n",
       "6       AGE             -0.005010\n",
       "7       DIS             -1.228034\n",
       "8       RAD              0.306087\n",
       "9       TAX             -0.012598\n",
       "10  PTRATIO             -0.828106\n",
       "11        B              0.013149\n",
       "12    LSTAT             -0.573296"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import model \n",
    "from sklearn.linear_model import ElasticNet \n",
    "\n",
    "# Train the model \n",
    "e_net = ElasticNet(alpha = .02,l1_ratio=.2) \n",
    "e_net.fit(x_train, y_train) \n",
    "\n",
    "# calculate the prediction and mean square error \n",
    "y_pred_elastic = e_net.predict(x_test) \n",
    "mean_squared_error = np.mean((y_pred_elastic - y_test)**2) \n",
    "print(\"Mean Squared Error on test set\", mean_squared_error) \n",
    "\n",
    "e_net_coeff = pd.DataFrame() \n",
    "e_net_coeff[\"Columns\"] = x_train.columns \n",
    "e_net_coeff['Coefficient Estimate'] = pd.Series(e_net.coef_) \n",
    "e_net_coeff \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
